{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>Analizando el conjunto de datos de la flor Iris</h1>\n",
    "\n",
    "Tenemos un conjunto de datos de la flor Iris la cuál tiene diversas especies (Setoda, Versicolor, etc).\n",
    "\n",
    "En el conjunto de datos tendremos 4 características:\n",
    "* Longitud del sépalo\n",
    "* Anchura del sépalo\n",
    "* Longitud del pétalo\n",
    "* Anchura del pétalo\n",
    "\n",
    "Haremos primeramente un perceptron para entrenar y clasificar las diferentes especies de flores de Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Repasaremos primero como funciona una neurona. \n",
    "![alt text](http://webspace.ship.edu/cgboer/neuronesp.gif)\n",
    "\n",
    "La neurona recibe un señales eléctricas que llegan a las dendrites. Estas señales son entonces integradas en el cuerpo de la célula, y si las señales acumuladas exceden un cierto umbral, una señal de salida será generada, la cuál será transmitida por el axón. \n",
    "\n",
    "Hace unos pocos años, Frank Rosenblatt publicó el primer concepto de regla de aprendizaje de perceptron basado en el modelo de neurona MCP. Con esta regla perceptron, Rosenblatt propusó un algoritmo que automáticamente aprendería los coeficientes de peso que es multiplicado por la entrada para saber si la neurona envia la señal, es decir, si sobrepasa el umbral.\n",
    "\n",
    "Nos basaremos un algoritmo de <strong>aprendizaje supervisado</strong>, es decir, a partir de muchas muestras entrenaremos a nuestro algoritmo de tal manera que sea capaz de predecir que especie de flor de Iris le estoy proporcionando sin saber explicitamente a que especie pertenece.\n",
    "\n",
    "\n",
    "\n",
    "De momento nos centraremos en que solo hay dos especies de flor Iris por lo tanto es un problema de clasificación binaria dónde tendremos dos clases, \"1 - clase positiva\" y \"-1 - clase negativa). Definiremos una función de activación φ(z), que combinara el valor de la entrada con la de los pesos, y nos dará una de las dos clases ya mencionadas.\n",
    "\n",
    "Si la salida de nuestra función de activación, es mayor que nuestro umbral θ (que habremos definido previamente), entonces la clase será 1, de lo contrario será -1. En el perceptron la función de activación es un único paso.\n",
    "\n",
    "Ahora implementaremos la clase perceptron, la cuál tendrá dos métodos principales que son el método fit y el método predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "    Parámetros\n",
    "    ---------\n",
    "    eta: float\n",
    "        Learning rate (entre 0.0 y 1.0)\n",
    "    n_iter: int\n",
    "        Pasos sobre el training dataset\n",
    "    \n",
    "    Atributos\n",
    "    ---------\n",
    "    w_: 1d-array\n",
    "        Pesos después de fitting\n",
    "    errors_: list\n",
    "        Número de clasificaciones erroneas en cada epoch.\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fir training data.\n",
    "        \n",
    "        Parámetros\n",
    "        ----------\n",
    "        X: {array-like}, shape = [n_samples, n_features]\n",
    "        Training vectors, dónde n_samples es el número de muestras \n",
    "        y n_features es el número de características\n",
    "        \n",
    "        y: array-like, shape = [n_samples]\n",
    "            Valores objetivo\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self: object\n",
    "        \"\"\"\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label después unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos inicializar nuestro percetron utilizando un rango de aprendizaje que le propocionaremos que es la variable eta y el número de epochs (pasos sobre el conjunto de entrenamiento) el cuál es la variable n_iter. Mediante el método fit, inicializaremos los pesos en el vector self.w_. \n",
    "\n",
    "Para probar nuestra implementación de perceptron, cargarémos dos clases de fores, Setoda y Versicolor del conjunto de datos de Iris. Aunque la regla perceptron no está restringida a dos dimensiones, únicamente consideramos las dos características de longitud de sépalo y longitud de pétalo para propositos de visualización. Aunque solo utilizamos dos clases de flores, el perceptron puede ser extendido a clasificación de multiples clases.\n",
    "\n",
    "Ahora obtendremos las flores:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Tracer\n",
    "Tracer()() #this one triggers the debugger\n",
    "print(\"HOLAO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
